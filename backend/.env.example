# OLI Backend Configuration

# Ollama LLM Settings
OLLAMA_MODEL=gpt-oss:120b-cloud
OLLAMA_BASE_URL=http://localhost:11434

# Alternative models you can use:
# OLLAMA_MODEL=qwen3:32b
# OLLAMA_MODEL=devstral:latest
# OLLAMA_MODEL=mistral-nemo:latest
# OLLAMA_MODEL=llama3.1:8b

